<div align="center">

# âš¡ Titan-AAS

### The High-Performance Asset Administration Shell Runtime

![Hero Banner](docs/images/hero_banner.png)

[![CI](https://github.com/hadijannat/titan-aas/actions/workflows/ci.yml/badge.svg)](https://github.com/hadijannat/titan-aas/actions/workflows/ci.yml)
[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![IDTA Compliant](https://img.shields.io/badge/IDTA-Release%2025--01-orange.svg)](https://industrialdigitaltwin.org)

**Production-grade AAS runtime optimized for read-heavy industrial workloads**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-documentation) â€¢ [ğŸ—ï¸ Architecture](#-architecture) â€¢ [ğŸ§ª Testing](#-testing)

</div>

---

## ğŸ¯ What is Titan-AAS?

> **For Non-Technical Readers**: Think of Titan-AAS as a "digital passport" system for industrial machines. Just like your passport contains all your identity information, an Asset Administration Shell (AAS) contains everything about a machineâ€”its specifications, maintenance history, sensor data, and more. Titan-AAS is the software that stores, searches, and delivers this information incredibly fast.

**For Technical Readers**: Titan-AAS is a contract-first AAS runtime implementing the IDTA Release 25-01 specification bundle. It uses a novel **write-validate / read-stream** architecture that:

- âœ… **Validates** all incoming data with Pydantic v2 strict mode
- âš¡ **Streams** canonical bytes directlyâ€”no object hydration on reads
- ğŸ”„ **Routes** requests through fast/slow paths based on query complexity
- ğŸ“¦ **Stores** both JSONB (for queries) and canonical bytes (for streaming)

---

## âœ¨ Key Features

![Features](docs/images/features.png)

| Feature | Description |
|---------|-------------|
| âš¡ **Blazing Fast Reads** | Stream raw bytes from Redis cacheâ€”sub-millisecond response times |
| ğŸ›¡ï¸ **IDTA Compliant** | Full implementation of Part 1 Metamodel + Part 2 API |
| ğŸ” **Enterprise Security** | OIDC authentication, RBAC authorization, rate limiting |
| ğŸ“Š **Observable** | OpenTelemetry tracing + Prometheus metrics built-in |
| ğŸ³ **Cloud Native** | Helm charts, Terraform modules for AWS/Azure/GCP |
| ğŸ”Œ **Real-time Events** | WebSocket + MQTT for live asset updates |

---

## ğŸ—ï¸ Architecture

![Architecture](docs/images/architecture.png)

### The Fast Path / Slow Path Pattern

```mermaid
flowchart LR
    subgraph Input
        R[HTTP Request]
    end
    
    subgraph Router["ğŸ”€ Smart Router"]
        D{Modifiers?}
    end
    
    subgraph Fast["âš¡ Fast Path"]
        RC[(Redis Cache)]
        STREAM[Stream Bytes]
    end
    
    subgraph Slow["ğŸ¢ Slow Path"]
        V[Pydantic Validate]
        P[Apply Projections]
    end
    
    R --> D
    D -->|"No modifiers"| RC
    D -->|"$value, $metadata, level=core"| V
    RC --> STREAM
    V --> P
    P --> STREAM
    STREAM --> O[Response]
    
    style Fast fill:#0d9488,stroke:#0f766e,color:#fff
    style Slow fill:#d97706,stroke:#b45309,color:#fff
```

### How It Works

1. **Write Path**: All writes go through Pydantic v2 validation â†’ JSON canonicalization â†’ stored as JSONB + canonical bytes
2. **Read Path (Fast)**: When no projections needed, stream raw bytes directly from Redis/Postgres
3. **Read Path (Slow)**: When modifiers like `$value` or `$metadata` are requested, hydrate model and transform
4. **Event Path**: Single writer pattern ensures consistent persistence and cache updates

---

## ğŸ“‹ Specification Baseline

| Specification | Version | Status |
|--------------|---------|--------|
| IDTA-01001 Part 1 Metamodel | v3.1.2 | âœ… Implemented |
| IDTA-01002 Part 2 API | v3.1.1 | âœ… Implemented |
| IDTA-01003-a Data Specification IEC 61360 | v3.1.1 | âœ… Implemented |
| IDTA-01004 Security | v3.0.1 | âœ… Implemented |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) (recommended) or pip
- PostgreSQL 15+ and Redis 7+ (for production)

### Development Setup

```bash
# Clone the repository
git clone https://github.com/hadijannat/titan-aas.git
cd titan-aas

# Install dependencies with uv
uv sync

# Run the development server
uv run -- uvicorn titan.api.app:create_app --factory --host 0.0.0.0 --port 8080 --reload
```

### Docker Compose (Full Stack)

```bash
# Start all services (API, PostgreSQL, Redis, Prometheus, Grafana)
docker compose -f deployment/docker-compose.yml up -d

# Access the services
# API:        http://localhost:8080
# Swagger UI: http://localhost:8080/docs
# Grafana:    http://localhost:3000 (admin/admin)
```

---

## ğŸ“‚ Repository Structure

```
titan-aas/
â”œâ”€â”€ ğŸ“ src/titan/           # Core runtime
â”‚   â”œâ”€â”€ api/                # FastAPI routers & middleware
â”‚   â”œâ”€â”€ core/               # Domain models & canonicalization
â”‚   â”œâ”€â”€ persistence/        # PostgreSQL repositories
â”‚   â”œâ”€â”€ cache/              # Redis caching layer
â”‚   â”œâ”€â”€ events/             # Event bus & worker
â”‚   â”œâ”€â”€ security/           # OIDC & RBAC
â”‚   â””â”€â”€ observability/      # Tracing & metrics
â”œâ”€â”€ ğŸ“ deployment/          # Docker & deploy artifacts
â”‚   â”œâ”€â”€ Dockerfile          # Multi-stage production build
â”‚   â””â”€â”€ docker-compose.yml  # Full development stack
â”œâ”€â”€ ğŸ“ charts/titan-aas/    # Helm chart for Kubernetes
â”œâ”€â”€ ğŸ“ terraform/           # IaC for AWS/Azure/GCP
â”œâ”€â”€ ğŸ“ tests/               # Comprehensive test suite
â”‚   â”œâ”€â”€ unit/               # 146 unit tests
â”‚   â”œâ”€â”€ integration/        # 32 integration tests
â”‚   â”œâ”€â”€ contract/           # OpenAPI conformance
â”‚   â””â”€â”€ load/               # Locust load tests
â””â”€â”€ ğŸ“ specs/               # Vendored IDTA OpenAPI specs
```

---

## ğŸ§ª Testing

```bash
# Run all unit tests
uv run -- pytest tests/unit -v

# Run integration tests (requires Docker)
uv run -- pytest tests/integration -v

# Run with coverage
uv run -- pytest --cov=titan --cov-report=html

# Run load tests
uv run -- locust -f tests/load/locustfile.py --headless -u 100 -r 10 -t 60s
```

| Test Suite | Tests | Status |
|------------|-------|--------|
| Unit | 146 | âœ… Passing |
| Integration | 32 | âœ… Passing |
| Contract | 13 | âœ… Passing |
| E2E | 15 | âœ… Passing |

---

## ğŸ”§ Configuration

Titan-AAS is configured via environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `TITAN_ENV` | Environment (development/production) | `development` |
| `DATABASE_URL` | PostgreSQL connection string | `postgresql+asyncpg://...` |
| `REDIS_URL` | Redis connection string | `redis://localhost:6379/0` |
| `OIDC_ISSUER` | OIDC provider URL | *(disabled)* |
| `ENABLE_TRACING` | Enable OpenTelemetry | `true` |
| `ENABLE_METRICS` | Enable Prometheus metrics | `true` |

---

## ğŸ“– Documentation

- [API Guide](docs/api-guide.md) - Complete API reference
- [Deployment Runbook](docs/deployment-runbook.md) - Production deployment guide
- [Architecture Decision Records](docs/adr/) - Design decisions

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting a PR.

```bash
# Development workflow
uv sync --group dev          # Install dev dependencies
uv run -- ruff check src/    # Lint
uv run -- ruff format src/   # Format
uv run -- mypy src/titan     # Type check
uv run -- pytest             # Test
```

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**Built with â¤ï¸ for the Industrial Digital Twin community**

[â¬† Back to top](#-titan-aas)

</div>
