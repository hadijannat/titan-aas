name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: "3.12"
  UV_VERSION: "0.9.24"

jobs:
  lint:
    name: Lint & Type Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --group dev

      - name: Run ruff linter
        run: uv run -- ruff check src/ tests/

      - name: Run ruff formatter check
        run: uv run -- ruff format --check src/ tests/

      - name: Run mypy type checker
        run: uv run -- mypy src/titan

  test-unit:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --group dev

      - name: Install coverage tools
        run: uv run -- pip install pytest-cov

      - name: Run unit tests with coverage
        run: |
          mkdir -p test-results
          uv run -- pytest tests/unit -v --tb=short \
            --cov=src/titan \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=40 \
            --junitxml=test-results/unit.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: coverage.xml
          flags: unittests
          fail_ci_if_error: false

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: test-results/unit.xml

  test-integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: titan
          POSTGRES_PASSWORD: titan
          POSTGRES_DB: titan
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --group dev

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql+asyncpg://titan:titan@localhost:5432/titan
          REDIS_URL: redis://localhost:6379/0
        run: |
          mkdir -p test-results
          uv run -- pytest tests/integration -v --tb=short --junitxml=test-results/integration.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: test-results/integration.xml

  test-contract:
    name: Contract & Conformance Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: titan
          POSTGRES_PASSWORD: titan
          POSTGRES_DB: titan
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --group dev

      - name: Run contract and conformance tests
        env:
          DATABASE_URL: postgresql+asyncpg://titan:titan@localhost:5432/titan
          REDIS_URL: redis://localhost:6379/0
        run: |
          mkdir -p test-results
          # Run both contract tests and Discovery integration tests for SSP coverage
          uv run -- pytest tests/contract tests/integration/test_discovery.py \
            -v --tb=short \
            --junitxml=test-results/conformance.xml

      - name: Generate conformance report
        if: always()
        run: |
          python scripts/generate_conformance_report.py \
            --input test-results/conformance.xml \
            --output conformance-report.json \
            --version ${{ github.ref_name || 'dev' }} \
            --min-conformance 0.95

      - name: Generate conformance summary
        if: always()
        run: |
          python scripts/generate_conformance_summary.py \
            --input conformance-report.json \
            --output conformance-summary.md

      - name: Validate conformance threshold
        run: |
          python -c "
          import json
          import sys

          with open('conformance-report.json') as f:
              report = json.load(f)

          rate = report['summary']['conformance_rate']
          threshold = 0.95

          print(f'Conformance rate: {rate:.1%}')
          print(f'Threshold: {threshold:.0%}')

          if rate < threshold:
              print(f'FAIL: Conformance rate {rate:.1%} below {threshold:.0%} threshold')
              sys.exit(1)

          print('PASS: Conformance meets threshold')
          "

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: conformance-test-results
          path: test-results/conformance.xml

      - name: Upload conformance report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: conformance-report
          path: |
            conformance-report.json
            conformance-summary.md

  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [lint, test-unit, test-integration, test-contract]
    permissions:
      contents: read
      security-events: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: deployment/Dockerfile
          push: false
          load: true
          tags: titan-aas:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Test Docker image health
        run: |
          # Create isolated network for container testing
          docker network create titan-test-net

          # Start PostgreSQL for health check
          docker run -d --name titan-test-postgres --network titan-test-net \
            -e POSTGRES_USER=titan \
            -e POSTGRES_PASSWORD=titan \
            -e POSTGRES_DB=titan \
            postgres:16-alpine

          # Start Redis for health check
          docker run -d --name titan-test-redis --network titan-test-net \
            redis:7-alpine

          # Wait for dependencies to be ready
          echo "Waiting for PostgreSQL and Redis..."
          sleep 10

          # Run Titan-AAS container
          docker run -d --name titan-test --network titan-test-net \
            -e DATABASE_URL=postgresql+asyncpg://titan:titan@titan-test-postgres:5432/titan \
            -e REDIS_URL=redis://titan-test-redis:6379/0 \
            -e TITAN_ENV=production \
            -e PUBLIC_HEALTH_ENDPOINTS=true \
            -p 8080:8080 \
            titan-aas:${{ github.sha }}

          # Wait for application to start
          echo "Waiting for Titan-AAS to start..."
          sleep 15

          # Verify health endpoints
          echo "Testing health endpoints..."
          curl -f http://localhost:8080/health/live || (docker logs titan-test && exit 1)
          curl -f http://localhost:8080/health/ready || (docker logs titan-test && exit 1)
          curl -f http://localhost:8080/docs || (docker logs titan-test && exit 1)

          echo "Container health check passed!"

          # Cleanup
          docker stop titan-test titan-test-redis titan-test-postgres
          docker rm titan-test titan-test-redis titan-test-postgres
          docker network rm titan-test-net

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.33.1
        with:
          image-ref: titan-aas:${{ github.sha }}
          format: sarif
          output: trivy-results.sarif
          vuln-type: os,library
          severity: CRITICAL,HIGH
          ignore-unfixed: true

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: trivy-results.sarif

      - name: Generate SBOM (CycloneDX)
        uses: anchore/sbom-action@v0
        with:
          image: titan-aas:${{ github.sha }}
          format: cyclonedx-json
          artifact-name: titan-aas-sbom.cdx.json

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync

      - name: Run bandit security scan
        run: uv run -- pip install bandit && uv run -- bandit -r src/titan -ll

      - name: Ensure pip is present in the venv
        run: uv run -- python -m ensurepip --upgrade

      - name: Run pip-audit dependency check
        env:
          PIPAPI_PYTHON_LOCATION: .venv/bin/python
        run: |
          uv run -- pip install pip-audit
          # Audit project dependencies only (skip system packages)
          uv run -- python -m pip install --upgrade pip
          uv run -- pip-audit --local --skip-editable \
            --ignore-vuln PYSEC-2024-230 \
            --ignore-vuln PYSEC-2024-225 \
            --ignore-vuln CVE-2024-23342

  load-test:
    name: Load Test (Performance Validation)
    runs-on: ubuntu-latest
    needs: [test-integration]
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: titan
          POSTGRES_PASSWORD: titan
          POSTGRES_DB: titan
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: uv sync --group dev

      - name: Start Titan-AAS server
        env:
          DATABASE_URL: postgresql+asyncpg://titan:titan@localhost:5432/titan
          REDIS_URL: redis://localhost:6379/0
          TITAN_ENV: production
          ENABLE_RATE_LIMITING: "false"
          PUBLIC_HEALTH_ENDPOINTS: "true"
          ALLOW_ANONYMOUS_ADMIN: "true"
        run: |
          uv run -- titan serve --host 0.0.0.0 --port 8080 &
          echo "Waiting for server to start..."
          sleep 10
          curl -f http://localhost:8080/health/live || exit 1
          echo "Server is ready"

      - name: Seed test data
        env:
          DATABASE_URL: postgresql+asyncpg://titan:titan@localhost:5432/titan
        run: |
          # Create some initial AAS and Submodel data for load testing
          for i in {1..100}; do
            curl -s -X POST http://localhost:8080/shells \
              -H "Content-Type: application/json" \
              -d "{\"modelType\":\"AssetAdministrationShell\",\"id\":\"urn:example:aas:seed-$i\",\"idShort\":\"SeedAAS$i\",\"assetInformation\":{\"assetKind\":\"Instance\",\"globalAssetId\":\"urn:example:asset:seed-$i\"}}" > /dev/null
          done
          for i in {1..100}; do
            curl -s -X POST http://localhost:8080/submodels \
              -H "Content-Type: application/json" \
              -d "{\"modelType\":\"Submodel\",\"id\":\"urn:example:sm:seed-$i\",\"idShort\":\"SeedSM$i\",\"submodelElements\":[{\"modelType\":\"Property\",\"idShort\":\"Value\",\"valueType\":\"xs:string\",\"value\":\"test\"}]}" > /dev/null
          done
          echo "Seeded 100 AAS and 100 Submodels"

      - name: Run load test
        env:
          LOAD_TEST_P99_MS: "300"
          LOAD_TEST_MAX_ERROR_RATE: "0.01"
        run: |
          uv run -- locust -f tests/load/locustfile.py \
            --host http://localhost:8080 \
            --headless \
            -u 100 \
            -r 20 \
            -t 60s \
            --html load-test-report.html \
            --csv load-test-results

      - name: Generate benchmark artifact
        if: always()
        run: |
          python -c "
          import json
          import csv
          from datetime import datetime, timezone

          # Read Locust stats
          stats = {}
          try:
              with open('load-test-results_stats.csv', 'r') as f:
                  reader = csv.DictReader(f)
                  for row in reader:
                      if row['Name'] == 'Aggregated':
                          stats = {
                              'requests_total': int(row.get('Request Count', 0)),
                              'failures_total': int(row.get('Failure Count', 0)),
                              'median_ms': float(row.get('Median Response Time', 0)),
                              'p95_ms': float(row.get('95%', 0)),
                              'p99_ms': float(row.get('99%', 0)),
                              'avg_ms': float(row.get('Average Response Time', 0)),
                              'min_ms': float(row.get('Min Response Time', 0)),
                              'max_ms': float(row.get('Max Response Time', 0)),
                              'rps': float(row.get('Requests/s', 0)),
                          }
          except FileNotFoundError:
              stats = {'error': 'Stats file not found'}

          benchmark = {
              'version': '${{ github.ref_name }}' or 'dev',
              'commit': '${{ github.sha }}',
              'generated_at': datetime.now(timezone.utc).isoformat(),
              'environment': {
                  'runner': 'github-actions',
                  'os': 'ubuntu-latest',
                  'python': '${{ env.PYTHON_VERSION }}',
              },
              'configuration': {
                  'users': 100,
                  'spawn_rate': 20,
                  'duration_seconds': 60,
                  'rate_limiting': False,
              },
              'dataset': {
                  'aas_count': 100,
                  'submodel_count': 100,
              },
              'results': stats,
              'thresholds': {
                  'p99_ms': 300,
                  'max_error_rate': 0.01,
              },
              'passed': stats.get('p99_ms', 999) <= 300 and
                       (stats.get('failures_total', 1) / max(stats.get('requests_total', 1), 1)) <= 0.01,
          }

          with open('benchmark-results.json', 'w') as f:
              json.dump(benchmark, f, indent=2)
          print('Benchmark artifact generated')
          print(json.dumps(benchmark, indent=2))
          "

      - name: Upload load test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: load-test-report
          path: |
            load-test-report.html
            load-test-results*.csv

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: benchmark-results.json
